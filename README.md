 В данной работе осуществляется анализ изменения качества классификации слов-омографов с увеличением длины анализируемого контекста омографа.
 
 Было использовано две смысловые группы из семейства омографов "лук": 1 - лук - оружие, 2 - лук - овощ. Данные содержатся в файле лук_датасет_processed.xlsx. Всего в датасете 611 строк (случаев употребления слов-омографов), 311 для класса 1 (лук - оружие) и 300 для класса 2 (лук - овощ).
 
 Векторизация текста проводится при помощи метода TF-IDF. Для классификации применяется модель логистической регрессии, метод опорных векторов, метод Random Forest и AdaBoost. Для оценки качества классификации применяются метрики precision, recall, f1-score для двух классов, а также accuracy, macro average, weighted average, матрица ошибок.
 Также была проведена кластеризация методом K-means, для оценки качества кластеризации были использованы silhouette score и adjusted rand index.
 Классификация\кластеризация была проведена для различной длины контекста, размером от 1 до 30 слов.

 ## Результаты
 ### Для логистической регрессии
 - Оптимальная длина контекста 5-6 слов
 - Максимальная accuracy (0.84) достигнута при длине контекста 5 слов, при этом остальные метрики достигают значения Precision: 0.79 (класс 1), 0.89 (класс 2), Recall: 0.90 (класс 1), 0.78 (класс 2), F1-score: 0.84 (оба класса).
 - При увеличении контекста с 1 до 5 слов accuracy повышается с 0.75 до 0.84 (+12%). Дальнейшее увеличение контекста (свыше 15 слов) не даёт значимого улучшения (accuracy колеблется в пределах 0.81-0.83).
 

### Для метода опорных векторов
 - Оптимальная длина контекста 5 слов, с повторным пиком на 26-30 словах.
 - Максимальная accuracy (0.84) достигнута при 5 словах: F1-score = 0.84 (оба класса), 26 словах: F1-score = 0.83-0.84, 29-30 словах: F1-score = 0.84
 - При увеличении контекста с 1 до 5 слов accuracy повышается с 0.76 до 0.84 (+10.5%). После 5 слов наблюдается небольшой спад (0.81-0.83), затем стабилизация на уровне 0.83-0.84 для длинных контекстов (20-30 слов).

### Для алгоритма Random Forest
 - Оптимальная длина контекста: 11 и 13 слов (пик accuracy = 0.77, F1-score = 0.77-0.79).
 - Максимальная accuracy (0.77) достигнута при 11 и 13 словах: для класса 1 Precision = 0.71, Recall = 0.90, F1 = 0.79, для класса 2 Precision = 0.88, Recall = 0.66, F1 = 0.75.
 - При увеличении контекста с 1 до 11 слов accuracy повышается с 0.70 до 0.77 (+10%). После 13 слов наблюдается спад (0.71-0.75), затем слабая стабилизация.

### Для алгоритма AdaBoost
- Оптимальная длина контекста 15 слов (пик accuracy = 0.75, F1-score = 0.78 для класса 1).
- Лучшие результаты - для контекста 15 слов Accuracy = 0.75, для класса 1 Precision = 0.68, Recall = 0.92, F1 = 0.78, для класса 2 Precision = 0.89, Recall = 0.59, F1 = 0.71
- Сильные колебания accuracy (от 0.66 до 0.75) без четкой зависимости от длины контекста. Наихудшие результаты при 7, 10 и 28 словах (accuracy ≈ 0.66-0.67).

### Для алгоритма кластеризации k-means
- Диапазон показателей составляет Silhouette Score: 0.0019-0.2348, Adjusted Rand Index (ARI): -0.0053 до 0.0531
- Увеличение контекста не улучшает кластеризацию
- Даже лучший результат (0.2348) говорит о слабой структуре кластеров

## Выводы

#### Сравнительный анализ 

| Алгоритм               | Accuracy (max) | F1-score (max) | Precision (max) | Recall (max) | Оптимальная длина контекста | Время обучения* |
|------------------------|---------------|---------------|----------------|-------------|----------------------------|----------------|
| **SVM (линейное ядро)** | 0.84          | 0.84          | 0.89           | 0.89        | 5, 26-30 слов              | Среднее        |
| **Логистическая регрессия** | 0.84      | 0.84          | 0.89           | 0.90        | 5 слов                     | Быстрое        |
| **Random Forest**       | 0.77          | 0.79          | 0.89           | 0.92        | 11-13 слов                 | Длительное     |
| **AdaBoost**            | 0.75          | 0.78          | 0.89           | 0.92        | 15 слов                    | Среднее        |

*Время обучения указано относительно других методов
- Длина контекста размером в 5-15 слов достаточна для большинства методов.
- Увеличение контекста >20 слов редко дает прирост качества.
- Топ-2 алгоритма: SVM (максимальная accuracy (0.84), стабильность для длинных контекстов), логистическая регрессия (сопоставимое качество (0.84), но только для коротких контекстов).
  
 
 

 
 
 

